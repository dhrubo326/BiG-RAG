# ============================================================================
# BiG-RAG - Algorithmic Mode Only (No RL Training)
# Bipartite Graph Retrieval-Augmented Generation
# For Windows/Linux/macOS + Python 3.11-3.13 + CPU/GPU
# TESTED & WORKING
# ============================================================================
#
# This requirements file contains ONLY dependencies needed for BiG-RAG
# Algorithmic Mode (works with GPT-4, Claude, etc. - no training required).
#
# If you need RL-Enhanced Mode, see requirements.txt instead.
# ============================================================================

# INSTALLATION STEPS:
# 1. conda create -n bigrag python==3.11.11
# 2. conda activate bigrag
# 3. pip install torch torchvision torchaudio
# 4. pip install -r requirements_graphrag_only.txt
# 5. python -m spacy download en_core_web_sm
# 6. python -c "import nltk; nltk.download('punkt'); nltk.download('stopwords')"

# Core Data Processing
numpy>=1.26.0
pandas>=2.0.0
pyarrow>=15.0.0
datasets

# Bipartite Graph and Knowledge Graph
networkx>=3.0  # Core: Bipartite graph structure with entity/relation partitions
# graspologic  # SKIP: needs gensim which requires C++ compiler
pyvis  # Optional: Graph visualization

# Embeddings and Vector Search (for dual-path retrieval)
# FlagEmbedding  # OPTIONAL: Local embeddings (BAAI/bge-large-en-v1.5). Use OpenAI text-embedding-3-large instead
# NOTE: If using script_api.py (old version with FAISS), uncomment FlagEmbedding above
# If using script_api_openai.py (new version), keep it commented (uses OpenAI embeddings)
faiss-cpu  # Vector similarity search for entity/relation embeddings (only needed for old script_api.py)
# hnswlib  # SKIP: requires C++ compiler on Python 3.13
nano-vectordb  # Lightweight vector database for BiG-RAG

# LLM API Integration (for Algorithmic Mode)
openai>=1.0.0  # For GPT-4/GPT-4o-mini (recommended)
tiktoken  # Token counting for OpenAI models
ollama  # Optional: Local LLM support (Qwen, Llama, etc.)

# NLP and Text Processing (for query analysis & decomposition)
transformers>=4.30.0  # LLM loading (optional for local models)
nltk  # Tokenization and text processing
spacy  # Query complexity analysis and dependency parsing
PyPDF2  # PDF document loading
jsonlines  # Dataset reading
xxhash  # Fast hashing for deduplication

# Async and Utilities (for concurrent processing)
aiohttp  # Async HTTP requests
aioboto3  # AWS S3 support (optional)
tqdm  # Progress bars for graph construction
tenacity  # Retry logic with exponential backoff

# API Server (optional - for retrieval API)
fastapi  # REST API framework
uvicorn[standard]  # ASGI server
pydantic>=2.0.0  # Data validation

# Utilities
python-dotenv  # Environment variable management
requests  # HTTP requests
colorama  # Colored terminal output

# ============================================================================
# WHAT'S EXCLUDED:
#
# Compiled packages (fail on Python 3.13 + Windows):
# - gensim (needs C++ compiler)
# - hnswlib (needs C++ compiler) - use faiss-cpu instead
# - graspologic (depends on gensim) - not critical for BiG-RAG
#
# RL Mode dependencies (excluded - see agent/, verl/ folders):
# - verl (RL training library)
# - vllm (inference optimization)
# - deepspeed (distributed training)
# - ray (distributed computing)
# These are only needed for RL-Enhanced Mode with small LLMs (1.5B-7B)
# ============================================================================
